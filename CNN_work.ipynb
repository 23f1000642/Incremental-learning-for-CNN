{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/23f1000642/Incremental-learning-for-CNN/blob/main/CNN_work.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fEdcavYJRxk"
      },
      "source": [
        "Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4VKPvUkcGIHv"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g4xfk-VDKJCG"
      },
      "outputs": [],
      "source": [
        "import torchvision\n",
        "from torchvision import  datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader\n",
        "import copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X17o39RYKyE1"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_n0g4CYLQ4S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f0ac08d-8383-4303-914f-47283cf724de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:01<00:00, 18.9MB/s]\n",
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 300kB/s]\n",
            "100%|██████████| 4.42M/4.42M [00:00<00:00, 5.54MB/s]\n",
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 8.59MB/s]\n"
          ]
        }
      ],
      "source": [
        "train_data = datasets.FashionMNIST('.data',train = True, download= True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KMTC32hMMIIp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "539db7c6-c0f0-4bc4-fdfc-17c7b0884648"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "len(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHFjUbN0MdZP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5779c627-3736-4440-ea02-fe4b2e16cad2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape: torch.Size([60000, 28, 28])\n",
            "Target: torch.Size([60000]) tensor([9, 0, 0,  ..., 3, 0, 5])\n",
            "Classes: ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
            "Class to idx: {'T-shirt/top': 0, 'Trouser': 1, 'Pullover': 2, 'Dress': 3, 'Coat': 4, 'Sandal': 5, 'Shirt': 6, 'Sneaker': 7, 'Bag': 8, 'Ankle boot': 9}\n"
          ]
        }
      ],
      "source": [
        "# help(datasets.FashionMNIST)\n",
        "print(\"Shape:\",train_data.data.shape)\n",
        "print(\"Target:\",train_data.targets.shape, train_data.targets)\n",
        "print(\"Classes:\",train_data.classes)\n",
        "print(\"Class to idx:\", train_data.class_to_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ua5_xWwOM7Cn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 45
        },
        "outputId": "1bc603b5-d853-4996-cff0-726f507af266"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAACD0lEQVR4AbWRz2sTQRTH38zszm42k6Q2TU2ixURstRdRasWC9FCsUE9SpIKnKl48+x94UOjNiyf/h4KgKN7TYgNKK+agjZS0wZDYbND90dn54VqxIWfxXebBB97nfecB/P9CAKkFAGT8ViEEh+9fLZZn7gde+E4AwkgAGYBEzl3btZz55y0tgSl/AHKYLhH85uJKdat2ebqyFmuOCun5laFIwcYXjvLRxq1nfRh3er0ESHAI1fvPYqF8oj9WxxO6hcAyWZhQV2fw6OvBbcEh2O/tlxTCjlRjgPtGAqwYcpN7GWUlPbppXepDTeB2AduQHONWpOzsi09GHxocPobUccZPh8RhcvfOy/V4IUQwigMIgFdeQHWb2BFEipzvxU6iBT9QALNPq8F3oYTnSRt8oN4iHOYcLk4UFs+GOEo0TZrlToXNqp7ZmkQw8yg3JIkrHI6C2lI1dawE9dQPP8HSDiJrRSF9IAFAZmT5+oNm+LU+nuVmispT6N6TbcYsMDONZg7nb9rl5NQU5pgCMq8YrUY6bDCa3t9hQShWt0rD3I0kNxWiE8aebiRH3E7bsEw7hTuTXqNrdSIRJfK9C8aH1bvNesioTcmB1P43JY2QcdeNRLkVR7nx8HjblYQaBGnTpCYC1AKq8ptLCMf55x6PZjAxJGrpPfWTgI58/LZW+fMJ8WXO5bond/j20Y3+sfkFaCTYdrBYeB0AAAAASUVORK5CYII=\n",
            "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APn+tbw1oNx4m8QWmkWx2yXD4LkZCADJJ+gFbviL4a63oc7COE3MW4hdn38duD976jNc9daDqllIsc9lKrMu4YGeMkdR7gj8KzcV7H8BtEvV16+1iWCeG1Wz8mOV02pIzupwCeuAp6Z98cZ90aIzLIlw0c0ZJ4KgjHoeOa+evjS9n/wnMcNxBPCYLKONFhA2FNzMpGenDcgd816V4K03wefC+m3NlpVhP+5QSXBiR5fMx825iMg5zwce3FdbOzTwgW90lu6uCm8eYrL02soIyCPQgggEdMGQ3cluiPNK0rJwrRQBNueuMkt+teNfGKxsdY8WWdxNqcNo66eieXMwVsb5DnH415Hp2rajpE5n02/urOUjBe3laMkehIPIrVm8eeLrhNknibVivoLtx/I1UPinxC3XXtUP1vJP8ay5JZJpGkldnduSzHJP41//2Q==\n"
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "train_data[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CRXHUpfnOgtU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "outputId": "4aeb482b-f150-4f9b-8d7d-bfc7fa142b95"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7b28a29f9910>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.imshow(train_data[0][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xdCE8DAhP3Ma"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7sIM0lb2Os9P"
      },
      "outputs": [],
      "source": [
        "# dir(transforms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5LeEVjioPT8_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08a6c142-1474-4614-aac5-5b845f66284f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([60000, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "train_data.data.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nv-kPW32QC49"
      },
      "source": [
        "Normalizing them so that the pixel values are in scale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0CEaB5bqPsQn"
      },
      "outputs": [],
      "source": [
        "transform  = transforms.ToTensor()\n",
        "# pipeline = first run transform 1, then run transform 2 , transform 3\n",
        "transform1 = transforms.Compose((transforms.ToTensor(),transforms.Normalize((0.5),(0.5))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DiGHhrNCQ8xG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdf9d7b1-fe47-436e-a22f-62f6a1d9a4e0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "type (train_data.data[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EeEDHvq5NprM"
      },
      "outputs": [],
      "source": [
        "train_data = datasets.FashionMNIST('.data', train = True, transform = transform1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t52c481NzBeK"
      },
      "source": [
        "Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "udJXht5fyv3N"
      },
      "outputs": [],
      "source": [
        "train_iter = DataLoader(train_data,batch_size = 100,shuffle = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-lB1lAY-zWgJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "ddfc6fc9-6f00-4f15-e814-d384ec1c691b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.utils.data.dataloader.DataLoader"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>torch.utils.data.dataloader.DataLoader</b><br/>def __init__(dataset: Dataset[_T_co], batch_size: Optional[int]=1, shuffle: Optional[bool]=None, sampler: Union[Sampler, Iterable, None]=None, batch_sampler: Union[Sampler[List], Iterable[List], None]=None, num_workers: int=0, collate_fn: Optional[_collate_fn_t]=None, pin_memory: bool=False, drop_last: bool=False, timeout: float=0, worker_init_fn: Optional[_worker_init_fn_t]=None, multiprocessing_context=None, generator=None, *, prefetch_factor: Optional[int]=None, persistent_workers: bool=False, pin_memory_device: str=&#x27;&#x27;, in_order: bool=True)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py</a>Data loader combines a dataset and a sampler, and provides an iterable over the given dataset.\n",
              "\n",
              "The :class:`~torch.utils.data.DataLoader` supports both map-style and\n",
              "iterable-style datasets with single- or multi-process loading, customizing\n",
              "loading order and optional automatic batching (collation) and memory pinning.\n",
              "\n",
              "See :py:mod:`torch.utils.data` documentation page for more details.\n",
              "\n",
              "Args:\n",
              "    dataset (Dataset): dataset from which to load the data.\n",
              "    batch_size (int, optional): how many samples per batch to load\n",
              "        (default: ``1``).\n",
              "    shuffle (bool, optional): set to ``True`` to have the data reshuffled\n",
              "        at every epoch (default: ``False``).\n",
              "    sampler (Sampler or Iterable, optional): defines the strategy to draw\n",
              "        samples from the dataset. Can be any ``Iterable`` with ``__len__``\n",
              "        implemented. If specified, :attr:`shuffle` must not be specified.\n",
              "    batch_sampler (Sampler or Iterable, optional): like :attr:`sampler`, but\n",
              "        returns a batch of indices at a time. Mutually exclusive with\n",
              "        :attr:`batch_size`, :attr:`shuffle`, :attr:`sampler`,\n",
              "        and :attr:`drop_last`.\n",
              "    num_workers (int, optional): how many subprocesses to use for data\n",
              "        loading. ``0`` means that the data will be loaded in the main process.\n",
              "        (default: ``0``)\n",
              "    collate_fn (Callable, optional): merges a list of samples to form a\n",
              "        mini-batch of Tensor(s).  Used when using batched loading from a\n",
              "        map-style dataset.\n",
              "    pin_memory (bool, optional): If ``True``, the data loader will copy Tensors\n",
              "        into device/CUDA pinned memory before returning them.  If your data elements\n",
              "        are a custom type, or your :attr:`collate_fn` returns a batch that is a custom type,\n",
              "        see the example below.\n",
              "    drop_last (bool, optional): set to ``True`` to drop the last incomplete batch,\n",
              "        if the dataset size is not divisible by the batch size. If ``False`` and\n",
              "        the size of dataset is not divisible by the batch size, then the last batch\n",
              "        will be smaller. (default: ``False``)\n",
              "    timeout (numeric, optional): if positive, the timeout value for collecting a batch\n",
              "        from workers. Should always be non-negative. (default: ``0``)\n",
              "    worker_init_fn (Callable, optional): If not ``None``, this will be called on each\n",
              "        worker subprocess with the worker id (an int in ``[0, num_workers - 1]``) as\n",
              "        input, after seeding and before data loading. (default: ``None``)\n",
              "    multiprocessing_context (str or multiprocessing.context.BaseContext, optional): If\n",
              "        ``None``, the default `multiprocessing context`_ of your operating system will\n",
              "        be used. (default: ``None``)\n",
              "    generator (torch.Generator, optional): If not ``None``, this RNG will be used\n",
              "        by RandomSampler to generate random indexes and multiprocessing to generate\n",
              "        ``base_seed`` for workers. (default: ``None``)\n",
              "    prefetch_factor (int, optional, keyword-only arg): Number of batches loaded\n",
              "        in advance by each worker. ``2`` means there will be a total of\n",
              "        2 * num_workers batches prefetched across all workers. (default value depends\n",
              "        on the set value for num_workers. If value of num_workers=0 default is ``None``.\n",
              "        Otherwise, if value of ``num_workers &gt; 0`` default is ``2``).\n",
              "    persistent_workers (bool, optional): If ``True``, the data loader will not shut down\n",
              "        the worker processes after a dataset has been consumed once. This allows to\n",
              "        maintain the workers `Dataset` instances alive. (default: ``False``)\n",
              "    pin_memory_device (str, optional): the device to :attr:`pin_memory` to if ``pin_memory`` is\n",
              "        ``True``.\n",
              "    in_order (bool, optional): If ``False``, the data loader will not enforce that batches\n",
              "        are returned in a first-in, first-out order. Only applies when ``num_workers &gt; 0``. (default: ``True``)\n",
              "\n",
              "\n",
              ".. warning:: If the ``spawn`` start method is used, :attr:`worker_init_fn`\n",
              "             cannot be an unpicklable object, e.g., a lambda function. See\n",
              "             :ref:`multiprocessing-best-practices` on more details related\n",
              "             to multiprocessing in PyTorch.\n",
              "\n",
              ".. warning:: ``len(dataloader)`` heuristic is based on the length of the sampler used.\n",
              "             When :attr:`dataset` is an :class:`~torch.utils.data.IterableDataset`,\n",
              "             it instead returns an estimate based on ``len(dataset) / batch_size``, with proper\n",
              "             rounding depending on :attr:`drop_last`, regardless of multi-process loading\n",
              "             configurations. This represents the best guess PyTorch can make because PyTorch\n",
              "             trusts user :attr:`dataset` code in correctly handling multi-process\n",
              "             loading to avoid duplicate data.\n",
              "\n",
              "             However, if sharding results in multiple workers having incomplete last batches,\n",
              "             this estimate can still be inaccurate, because (1) an otherwise complete batch can\n",
              "             be broken into multiple ones and (2) more than one batch worth of samples can be\n",
              "             dropped when :attr:`drop_last` is set. Unfortunately, PyTorch can not detect such\n",
              "             cases in general.\n",
              "\n",
              "             See `Dataset Types`_ for more details on these two types of datasets and how\n",
              "             :class:`~torch.utils.data.IterableDataset` interacts with\n",
              "             `Multi-process data loading`_.\n",
              "\n",
              ".. warning:: See :ref:`reproducibility`, and :ref:`dataloader-workers-random-seed`, and\n",
              "             :ref:`data-loading-randomness` notes for random seed related questions.\n",
              "\n",
              ".. warning:: Setting `in_order` to `False` can harm reproducibility and may lead to a skewed data\n",
              "             distribution being fed to the trainer in cases with imbalanced data.\n",
              "\n",
              ".. _multiprocessing context:\n",
              "    https://docs.python.org/3/library/multiprocessing.html#contexts-and-start-methods</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 130);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "type(train_iter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PIXKoroCzjpo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9511813-211e-4f2b-abae-c46866f22ed3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([9, 7, 4, 8, 6, 3, 2, 5, 3, 5, 3, 2, 3, 6, 4, 8, 2, 8, 9, 7, 9, 3, 5, 8,\n",
            "        4, 9, 8, 8, 2, 6, 7, 3, 0, 4, 3, 0, 9, 3, 4, 9, 6, 6, 5, 4, 3, 7, 4, 7,\n",
            "        6, 2, 8, 6, 6, 7, 2, 7, 0, 5, 7, 6, 3, 8, 6, 4, 5, 8, 3, 1, 0, 6, 2, 1,\n",
            "        2, 6, 2, 2, 6, 8, 4, 5, 2, 7, 2, 0, 2, 1, 9, 9, 0, 7, 8, 4, 9, 3, 6, 5,\n",
            "        0, 8, 3, 3])\n"
          ]
        }
      ],
      "source": [
        "for features, labels in train_iter:\n",
        "  print(labels)\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SYiGfb2u16wp"
      },
      "outputs": [],
      "source": [
        "# nn.Linear()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mg9_KUZgPuRk"
      },
      "outputs": [],
      "source": [
        "iterator = iter(train_iter)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6g_ls06VQA9h"
      },
      "outputs": [],
      "source": [
        "feat, lab = next (iterator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ib1SVYm4QLvR"
      },
      "outputs": [],
      "source": [
        "x = feat[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XCEhf4PAQTvl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9c0d654-b651-4e8e-8c27-5d961c6b7a2f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "x.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otQKXOrBQ3i6"
      },
      "source": [
        "# CNN\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RvV4_lnYQWZy"
      },
      "outputs": [],
      "source": [
        "conv = nn.Conv2d(1,6,5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_S3bRwvmR5cU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84618ecf-6271-4657-df50-1fd292846b69"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6, 1, 5, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "conv.weight.shape     # these are the weight parameter tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1PCTyoP0SG6D"
      },
      "outputs": [],
      "source": [
        "x1 = conv(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SQz_-ujuSPdK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b2096ca-7e05-4aff-83f6-209c38ce4d5c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6, 24, 24])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "x1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wsJBJcpBSRC7"
      },
      "outputs": [],
      "source": [
        "pooling = nn.MaxPool2d(2,2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ic_H7Tn4Tf6D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b64a8c01-fa49-4a47-92c6-2c9bc95eba65"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6, 12, 12])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "x2 = pooling(x1)\n",
        "x2.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g6B0EvWc3hjG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df5ec782-4849-44a3-b20c-4e51fbcd7b6c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6, 4, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "## simply coding each step in CNN sequentially\n",
        "x = feat[0]\n",
        "x = nn.Conv2d(1, 6, 5)(x)\n",
        "x = nn.MaxPool2d(2, 2)(x)\n",
        "x = nn.Conv2d(6, 6, 5)(x)\n",
        "x = nn.MaxPool2d(2, 2)(x)\n",
        "x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EAQEbOR23mTN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b49f88af-0caf-4cc5-a93b-cf603d83c9b0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.5426, 0.5200, 0.4693, 0.4166],\n",
              "         [0.3276, 0.3198, 0.3515, 0.2754],\n",
              "         [0.5301, 0.4914, 0.6053, 0.6179],\n",
              "         [0.6699, 0.7153, 0.6615, 0.7438]],\n",
              "\n",
              "        [[0.1099, 0.0502, 0.0866, 0.1011],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0508, 0.1857, 0.1759, 0.2056],\n",
              "         [0.5316, 0.4339, 0.4040, 0.3864]],\n",
              "\n",
              "        [[0.3295, 0.3358, 0.3689, 0.4476],\n",
              "         [0.2096, 0.1924, 0.2126, 0.3987],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0295],\n",
              "         [0.0211, 0.0341, 0.0587, 0.0240]],\n",
              "\n",
              "        [[0.0000, 0.1073, 0.0699, 0.0000],\n",
              "         [0.1261, 0.1535, 0.2112, 0.3389],\n",
              "         [0.0684, 0.0862, 0.0637, 0.1663],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000]],\n",
              "\n",
              "        [[0.3218, 0.4180, 0.4595, 0.5492],\n",
              "         [0.4336, 0.4633, 0.4342, 0.5753],\n",
              "         [0.2365, 0.1725, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000]],\n",
              "\n",
              "        [[0.3599, 0.3909, 0.3894, 0.3383],\n",
              "         [0.3234, 0.2388, 0.0832, 0.1855],\n",
              "         [0.0332, 0.0000, 0.0115, 0.0000],\n",
              "         [0.2196, 0.2283, 0.2608, 0.2021]]], grad_fn=<ReluBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "F.relu(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrLhf6M1UDmQ"
      },
      "source": [
        "Define CNN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NsfSZDA6TpKj"
      },
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN,self).__init__()\n",
        "\n",
        "    self.fc1 = nn.Linear(6*4*4, 80)\n",
        "    self.fc2 = nn.Linear(80,20)\n",
        "    self.fc3 = nn.Linear(20,10)\n",
        "\n",
        "    #in_channels = 1 , out_channnels = 6 , kernal_size = 5\n",
        "\n",
        "    self.conv1 = nn.Conv2d(1,6,5)\n",
        "     # applying the max pooling with a kernal size 2\n",
        "    self.pool = nn.MaxPool2d(2,2)\n",
        "    self.conv2 = nn.Conv2d(6,6,5)\n",
        "\n",
        "    #THESE ABOVE ARE THE COMPONENTS OF YOUR MODERL\n",
        "# FWD PASS WILL DEFINE THE ARCHITECTURE OF YOUR MODEL\n",
        "  def forward(self,x):\n",
        "    x = self.conv1(x)     ## 6 x 24 x 24\n",
        "    x = F.relu(x)        ## 6 x 24 x 24\n",
        "    x = self.pool(x)     ## 6 x 12 x 12\n",
        "    x = self.conv2(x)     ## 6 x 8 x 8\n",
        "    x = F.relu(x)        ## 6 x 8 x 8\n",
        "    x = self.pool(x)     ## 6 x 4 x4\n",
        "    x = x.view(-1,6*4*4)  ## x.flatten()  x.Flatten()\n",
        "    x = self.fc1(x)       ## 1 x80\n",
        "    x = F.relu(x)          ## 1 x80\n",
        "    x = self.fc2(x)       ## 1x 20\n",
        "    x = self.fc3(x)      ## 1x 20\n",
        "\n",
        "    return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FL_QmOoWwKeK"
      },
      "outputs": [],
      "source": [
        "Model = CNN()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5WdFFLLTx08u"
      },
      "outputs": [],
      "source": [
        "x = feat[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_zzsSpzynuX"
      },
      "outputs": [],
      "source": [
        " x =  Model(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OM-nf2EI8_zr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "673d4c7c-68fc-467e-e7db-c575143614e4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "x.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLey-9Niy9jM"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WxnSAqMYx7gH"
      },
      "outputs": [],
      "source": [
        "# CROSS ENTROPY LOSS = SOFTMAX + CROSSS ENTROPPY LOSS\n",
        "\n",
        "Loss = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(Model.parameters(),lr = 0.1 , momentum = 0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "agNToAZvyB1f"
      },
      "outputs": [],
      "source": [
        "#  1 EPOCH = PASS THROUGH ENTIRE DATA SET"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnpBSo7J3LPH"
      },
      "source": [
        "total points = 60000\n",
        "\n",
        "batch size = 100\n",
        "\n",
        "total batches = 600"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQU3hZC90aJ_",
        "outputId": "4ab51400-bca3-4d80-8521-36ac23bf3184"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  tensor(0.8143)\n",
            "Accuracy:  tensor(0.8292)\n",
            "Accuracy:  tensor(0.8330)\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(3):\n",
        "  ## HERE EPOCH STARTS -- so refresh all your counters\n",
        "  total_correct_pts = 0\n",
        "\n",
        "  for features, labels in train_iter:   ## will run for 600 batches\n",
        "\n",
        "    optimizer.zero_grad()   ## in order to remove any previous gradient info\n",
        "\n",
        "    output = Model(features)  ## forward pass     100x10 max along dim=1\n",
        "\n",
        "    ls = Loss(output, labels)   ## compute loss\n",
        "\n",
        "    ls.backward()   ## back propagate the loss\n",
        "\n",
        "    optimizer.step()  ## update the parameters\n",
        "\n",
        "    corr = torch.argmax(output, axis = 1) == torch.as_tensor(labels)\n",
        "\n",
        "    total_correct = torch.count_nonzero(corr)\n",
        "    total_correct_pts += total_correct\n",
        "\n",
        "  print(\"Accuracy: \", total_correct_pts/60000)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analyzing the  Model's Performance usingg incremental learning\n"
      ],
      "metadata": {
        "id": "VQyrGCRWytjA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### spliting the dataset into task 1 and task 2"
      ],
      "metadata": {
        "id": "SN-R_V06OLLm"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MUQBeJk-OKoq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Split MNIST dataset into Task 1 (digits 0-4) and Task 2 (digits 5-9)\n",
        "def split_mnist():\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5,), (0.5,))\n",
        "    ])\n",
        "\n",
        "    mnist_dataset = datasets.MNIST(root=\"./data\", train=True, transform=transform, download=True)\n",
        "\n",
        "    # Split data\n",
        "    task1_data = [(img, label) for img, label in mnist_dataset if label < 5]\n",
        "    task2_data = [(img, label) for img, label in mnist_dataset if label >= 5]\n",
        "# task1_test_dataset = Subset(mnist_test, task1_indices)\n",
        "    # Create DataLoaders\n",
        "    task1_loader = DataLoader(task1_data, batch_size=100, shuffle=True)\n",
        "    task2_loader = DataLoader(task2_data, batch_size=100, shuffle=True)\n",
        "    return task1_loader, task2_loader\n",
        "\n",
        "# Create DataLoaders\n",
        "train_iter_task1, train_iter_task2 = split_mnist()\n"
      ],
      "metadata": {
        "id": "1qqW3vog72cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e630a7d-2969-48bf-d5f8-d5693716ce5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 52.6MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 1.64MB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 13.1MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 7.42MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify the DataLoaders for Task 1 and Task 2\n",
        "for images, labels in train_iter_task1:\n",
        "    print(f\"Task 1 - Batch size: {images.size(0)}, Labels: {labels[:10]}\")\n",
        "    break  # Check only the first batch\n",
        "\n",
        "for images, labels in train_iter_task2:\n",
        "    print(f\"Task 2 - Batch size: {images.size(0)}, Labels: {labels[:10]}\")\n",
        "    break  # Check only the first batch\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vufh2wr4EaEz",
        "outputId": "3835431c-e481-4010-85d6-9535a20c26b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task 1 - Batch size: 100, Labels: tensor([4, 1, 1, 0, 1, 3, 1, 2, 3, 3])\n",
            "Task 2 - Batch size: 100, Labels: tensor([6, 9, 6, 9, 5, 6, 7, 9, 6, 9])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define the neural network\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self, input_size=28*28, hidden_size=128, output_size=10):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)  # Flatten the input\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "uvuGjFuRE45i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking for GPU availability and set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DosMi3nBF5oh",
        "outputId": "4e97cc26-19db-4ccc-cf42-2a1a7b0a36bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleNN()\n",
        "model.to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBqgvV7BF-SD",
        "outputId": "c6624b6b-92b3-48e9-d4eb-e8fcd53928a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SimpleNN(\n",
              "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
              "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, optimizer, criterion, num_epochs=5):\n",
        "    model.train()  # Set the model to training mode\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for features, labels in train_loader:\n",
        "            features, labels = features.to(device), labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(features)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Backward pass and optimization\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Accumulate metrics\n",
        "            total_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "\n",
        "        accuracy = correct / total\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss:.4f}, Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "-B8vWt3DGCqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####### Hyperparameter tune"
      ],
      "metadata": {
        "id": "chcbbP2-Okif"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "learning_rate = 0.00005\n",
        "num_epochs = 5\n",
        "\n",
        "# Loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n"
      ],
      "metadata": {
        "id": "_-NsiVYMFiNR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Trainin on 1 task"
      ],
      "metadata": {
        "id": "naVgzi6mOsDV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train on Task 1\n",
        "print(\"Training on Task 1...\")\n",
        "train_model(model, train_iter_task1, optimizer, criterion, num_epochs=num_epochs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93xNBnQsFi7g",
        "outputId": "f32c3c90-ab71-41f0-facb-8e4cd76654a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on Task 1...\n",
            "Epoch [1/5], Loss: 258.7517, Accuracy: 0.8380\n",
            "Epoch [2/5], Loss: 80.7007, Accuracy: 0.9416\n",
            "Epoch [3/5], Loss: 56.7758, Accuracy: 0.9519\n",
            "Epoch [4/5], Loss: 47.3288, Accuracy: 0.9577\n",
            "Epoch [5/5], Loss: 42.1500, Accuracy: 0.9617\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## COMPUTING FISHER TECHNIQUE"
      ],
      "metadata": {
        "id": "c71K8KhcO7LM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_fisher_information(model, data_loader, criterion):\n",
        "\n",
        "    fisher_matrix = {}\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "    # Initialize Fisher matrix with zeros for each parameter\n",
        "    for name, param in model.named_parameters():\n",
        "        fisher_matrix[name] = torch.zeros_like(param, device=device)\n",
        "\n",
        "    print(\"Computing Fisher Information...\")  # Debug: Track progress\n",
        "    for batch_idx, (features, labels) in enumerate(data_loader):\n",
        "        features, labels = features.to(device), labels.to(device)\n",
        "\n",
        "        model.zero_grad()  # Reset gradients\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()  # Compute gradients\n",
        "\n",
        "        # Update Fisher matrix with squared gradients\n",
        "        for name, param in model.named_parameters():\n",
        "            if param.grad is not None:\n",
        "                fisher_matrix[name] += param.grad.pow(2) * len(labels)\n",
        "\n",
        "        # Debug: Print intermediate results for the first batch\n",
        "        if batch_idx == 0:\n",
        "            print(\"Debug - First Batch Gradients:\")\n",
        "            for name, param in model.named_parameters():\n",
        "                if param.grad is not None:\n",
        "                    print(f\"{name}: Grad Mean={param.grad.mean().item()}, Grad Std={param.grad.std().item()}\")\n",
        "\n",
        "    # Average Fisher values across all batches\n",
        "    for name in fisher_matrix:\n",
        "        fisher_matrix[name] /= len(data_loader.dataset)  # Normalize by dataset size\n",
        "\n",
        "        # Debug: Print summary statistics for Fisher values\n",
        "        print(f\"Fisher Matrix - {name}: Mean={fisher_matrix[name].mean().item()}, \"\n",
        "              f\"Std={fisher_matrix[name].std().item()}, \"\n",
        "              f\"Max={fisher_matrix[name].max().item()}, \"\n",
        "              f\"Min={fisher_matrix[name].min().item()}\")\n",
        "\n",
        "    return fisher_matrix\n"
      ],
      "metadata": {
        "id": "R6M76SWlLDql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Computing Fisher Information for Task 1...\")\n",
        "fisher_matrix_task1 = compute_fisher_information(model, train_iter_task1, criterion)\n",
        "prev_params_task1 = {name: param.clone() for name, param in model.named_parameters()}\n",
        "print(\"Fisher Information computed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVzyunZHGS72",
        "outputId": "92d682c2-a294-4617-cf69-968a9361623b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing Fisher Information for Task 1...\n",
            "Computing Fisher Information...\n",
            "Debug - First Batch Gradients:\n",
            "fc1.weight: Grad Mean=1.2104260349588003e-05, Grad Std=0.0012966817012056708\n",
            "fc1.bias: Grad Mean=-2.1475007088156417e-05, Grad Std=0.0012277872301638126\n",
            "fc2.weight: Grad Mean=-6.991399681410826e-10, Grad Std=0.012020401656627655\n",
            "fc2.bias: Grad Mean=-7.545167823863608e-10, Grad Std=0.005920010153204203\n",
            "Fisher Matrix - fc1.weight: Mean=2.3680247522861464e-06, Std=1.5529284382864716e-06, Max=9.267662790080067e-06, Min=0.0\n",
            "Fisher Matrix - fc1.bias: Mean=2.5721210477058776e-06, Std=1.6827787021611584e-06, Max=8.720295227249153e-06, Min=0.0\n",
            "Fisher Matrix - fc2.weight: Mean=0.00023909550509415567, Std=0.00042952026706188917, Max=0.004196864552795887, Min=0.0\n",
            "Fisher Matrix - fc2.bias: Mean=6.049380681361072e-05, Std=7.70705082686618e-05, Max=0.00021167237719055265, Min=1.3915341101622403e-10\n",
            "Fisher Information computed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ewc_loss(model, fisher_matrix, prev_params, ewc_lambda):\n",
        "    loss = 0\n",
        "    for name, param in model.named_parameters():\n",
        "        if name in fisher_matrix:\n",
        "            loss += (fisher_matrix[name] * (param - prev_params[name]).pow(2)).sum()\n",
        "    return ewc_lambda * loss\n"
      ],
      "metadata": {
        "id": "mNysPOllGVnO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_with_ewc(model, train_loader, optimizer, criterion, fisher_matrix, prev_params, ewc_lambda, num_epochs=5):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for features, labels in train_loader:\n",
        "            features, labels = features.to(device), labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(features)\n",
        "            task_loss = criterion(outputs, labels)\n",
        "\n",
        "            #  EWC loss\n",
        "            reg_loss = ewc_loss(model, fisher_matrix, prev_params, ewc_lambda)\n",
        "            loss = task_loss + reg_loss\n",
        "\n",
        "            # Backward pass and optimization\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Accumulate metrics\n",
        "            total_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "      # Print epoch results\n",
        "        accuracy = correct / total\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss:.4f}, Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "tbAdpmkYGYrP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training on task 2 with EWC"
      ],
      "metadata": {
        "id": "IuBZqbwtPNQm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training on Task 2 with EWC...\")\n",
        "\n",
        "\n",
        "ewc_lambda = 1000000\n",
        "\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.00005)\n",
        "\n",
        "def train_with_ewc_and_logging(\n",
        "    model, train_loader, prev_params, fisher_matrix, optimizer, criterion,\n",
        "    ewc_lambda, num_epochs):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss, ewc_loss_value, task_loss_value = 0, 0, 0\n",
        "        correct, total = 0, 0\n",
        "\n",
        "        for features, labels in train_loader:\n",
        "            features, labels = features.to(device), labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(features)\n",
        "            task_loss = criterion(outputs, labels)\n",
        "\n",
        "            # Computing EWC loss\n",
        "            ewc_loss = 0\n",
        "            for name, param in model.named_parameters():\n",
        "                if name in fisher_matrix:\n",
        "                    fisher = fisher_matrix[name]\n",
        "                    prev_param = prev_params[name]\n",
        "                    ewc_loss += torch.sum(fisher * (param - prev_param).pow(2))\n",
        "\n",
        "            # Total loss\n",
        "            loss = task_loss + ewc_lambda * ewc_loss\n",
        "\n",
        "            # Backward pass and optimization\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Accumulate metrics\n",
        "            total_loss += loss.item()\n",
        "            ewc_loss_value += ewc_loss.item()\n",
        "            task_loss_value += task_loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "\n",
        "        accuracy = correct / total\n",
        "        print(\n",
        "            f\"Epoch [{epoch + 1}/{num_epochs}], \"\n",
        "            f\"Total Loss: {total_loss:.4f}, Task Loss: {task_loss_value:.4f}, \"\n",
        "            f\"EWC Loss: {ewc_loss_value:.4f}, Accuracy: {accuracy:.4f}\"\n",
        "        )\n",
        "\n",
        "\n",
        "train_with_ewc_and_logging(\n",
        "    model, train_iter_task2, prev_params_task1, fisher_matrix_task1,\n",
        "    optimizer, criterion, ewc_lambda, num_epochs=num_epochs\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-dYnOXbNFTT",
        "outputId": "23cf4e94-b79e-43af-f45c-9dfe0d7f8126"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on Task 2 with EWC...\n",
            "Epoch [1/5], Total Loss: 4028.0728, Task Loss: 2214.9615, EWC Loss: 0.0018, Accuracy: 0.0000\n",
            "Epoch [2/5], Total Loss: 11902.1564, Task Loss: 1269.1366, EWC Loss: 0.0106, Accuracy: 0.0006\n",
            "Epoch [3/5], Total Loss: 22520.4428, Task Loss: 740.4959, EWC Loss: 0.0218, Accuracy: 0.0721\n",
            "Epoch [4/5], Total Loss: 30347.1897, Task Loss: 545.6586, EWC Loss: 0.0298, Accuracy: 0.2504\n",
            "Epoch [5/5], Total Loss: 35411.5105, Task Loss: 471.7372, EWC Loss: 0.0349, Accuracy: 0.4102\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, data_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for features, labels in data_loader:\n",
        "            features, labels = features.to(device), labels.to(device)\n",
        "            outputs = model(features)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "    return correct / total\n"
      ],
      "metadata": {
        "id": "jine5kgUGdef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Evaluating on Task 1...\")\n",
        "accuracy_task1 = evaluate(model, train_iter_task1)\n",
        "print(f\"Accuracy on Task 1: {accuracy_task1:.4f}\")\n",
        "\n",
        "print(\"Evaluating on Task 2...\")\n",
        "accuracy_task2 = evaluate(model, train_iter_task2)\n",
        "print(f\"Accuracy on Task 2: {accuracy_task2:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYkUZxn_GuLy",
        "outputId": "706922f7-704c-47f0-eb3a-51a8870f3731"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating on Task 1...\n",
            "Accuracy on Task 1: 0.7484\n",
            "Evaluating on Task 2...\n",
            "Accuracy on Task 2: 0.4618\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WTPiX9oHKci7"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOGZIT8bWsNrEmarCl9VFc5",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}